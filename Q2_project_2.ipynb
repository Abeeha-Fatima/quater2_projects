{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP70YijB4CWhX+HC4CscXu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abeeha-Fatima/quater2_projects/blob/main/Q2_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUWP3EU2BHxJ",
        "outputId": "c72ffb72-ed52-48ba-e0c5-ed16a94739d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-pinecone langchain-google-genai # install and setup pinecone and langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone,ServerlessSpec\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n",
        "pc = Pinecone()"
      ],
      "metadata": {
        "id": "2a_GA5r9Bqmi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"rag-project\" # initialize index\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "    print(f\"Index '{index_name}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Index '{index_name}' already exists.\")\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0p7LdBSB02K",
        "outputId": "c4490941-a617-4684-cd2b-66ae005b9717"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'rag-project' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings # setup embeddings\n",
        "from google.auth.credentials import AnonymousCredentials\n",
        "import os\n",
        "\n",
        "credentials = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] = credentials\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=credentials,\n",
        ")\n",
        "\n",
        "vector = embeddings.embed_query(\"we are building a RAG Text\")\n",
        "\n",
        "print(vector[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDxT7sObj-Eh",
        "outputId": "f19204a2-a3ff-45c7-a72e-a99c0f4ac306"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04060795158147812, -0.04385491460561752, -0.05683692544698715, -0.021194666624069214, 0.010449625551700592]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore # setup vector store\n",
        "vector_store = PineconeVectorStore(\n",
        "    index=index,\n",
        "    embedding=embeddings\n",
        "    )"
      ],
      "metadata": {
        "id": "g8mqMRrvkUp3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document # setup and upload documents\n",
        "\n",
        "# Define each document\n",
        "document_1 = Document(\n",
        "    page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "    metadata={\"source\": \"mammal-pets-doc\"},\n",
        ")\n",
        "document_2 = Document(\n",
        "    page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "    metadata={\"source\": \"mammal-pets-doc\"},\n",
        ")\n",
        "document_3 = Document(\n",
        "    page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "    metadata={\"source\": \"fish-pets-doc\"},\n",
        ")\n",
        "document_4 = Document(\n",
        "    page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "    metadata={\"source\": \"bird-pets-doc\"},\n",
        ")\n",
        "document_5 = Document(\n",
        "    page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "    metadata={\"source\": \"mammal-pets-doc\"},\n",
        ")\n",
        "\n",
        "# Create the list\n",
        "documents = [document_1, document_2, document_3, document_4, document_5]\n"
      ],
      "metadata": {
        "id": "Pn1QWWE5kagX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = [str(uuid4()) for _ in range(len(documents))]\n",
        "vector_store.add_documents(documents=documents,id=user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2my3eN59fKW",
        "outputId": "a1e22dbb-17df-4757-aaf8-ce9748f45a5a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9d2af9ec-fbe6-4e25-8bc0-7f3ac482e74c',\n",
              " 'a3a26601-529d-43dd-80ce-609470a60b0c',\n",
              " '005b2144-ae0a-496e-82b5-4132bd50d804',\n",
              " '9aea77f9-c2bd-429b-852b-13f27299b225',\n",
              " '988cae84-ff9a-46ef-a2fb-0ffc6a2e3091']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup retriver\n",
        "results = vector_store.similarity_search(\n",
        "   \"Goldfish are popular pets for beginners\",\n",
        "    k=3,\n",
        "    filter={\"source\": \"fish-pets-doc\"},\n",
        ")\n",
        "\n",
        "# Iterating over the results and printing the content of each matching document along with its metadata\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7JweISQ2hOO",
        "outputId": "9c6fc250-a644-4929-9adc-cbd68f6a6e41"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Goldfish are popular pets for beginners, requiring relatively simple care. [{'source': 'fish-pets-doc'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Cats are independent pets that often enjoy their own space.\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"mammal-pets-doc\"}\n",
        ")\n",
        "\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmbOIJ8T38LU",
        "outputId": "be87af76-c778-4d1f-a28d-12454cff9d87"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.827372] Cats are independent pets that often enjoy their own space. [{'source': 'mammal-pets-doc'}]\n",
            "* [SIM=0.626672] Rabbits are social animals that need plenty of space to hop around. [{'source': 'mammal-pets-doc'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setup LLM\n",
        "import langchain.chat_models\n",
        "import langchain_google_genai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "JyT_YUsGuYIR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(genai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inxn5uN-vm6Z",
        "outputId": "3b22fde9-6e9d-49b4-af6d-ce6b06b038e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AqaInput',\n",
              " 'AqaOutput',\n",
              " 'ChatGoogleGenerativeAI',\n",
              " 'DoesNotExistsException',\n",
              " 'GenAIAqa',\n",
              " 'GoogleGenerativeAI',\n",
              " 'GoogleGenerativeAIEmbeddings',\n",
              " 'GoogleVectorStore',\n",
              " 'HarmBlockThreshold',\n",
              " 'HarmCategory',\n",
              " '__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_common',\n",
              " '_enums',\n",
              " '_function_utils',\n",
              " '_genai_extension',\n",
              " '_image_utils',\n",
              " 'chat_models',\n",
              " 'embeddings',\n",
              " 'genai_aqa',\n",
              " 'google_vector_store',\n",
              " 'llms']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#combine retriver and LLM\n",
        "!pip install -qU langchain-community\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_core.documents import Document\n",
        "from langchain.chains import RetrievalQA\n",
        "from uuid import uuid4"
      ],
      "metadata": {
        "id": "cHSEzDGzt8aQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key=os.environ['GEMINI_API_KEY'],\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "69bu8NBWwTjQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup for a function for llm to answer based on the rag database we set earlier\n",
        "def answer_to_user_by_model(query: str):\n",
        "  result = vector_store.similarity_search_with_score(query, k=2)\n",
        "  print(len(result))\n",
        "  final_answer = llm.invoke(f\"ANSWER THIS USER QUERY:{query},HERE ARE SOME REFERENCE ANSWER{result}\")\n",
        "  return final_answer\n"
      ],
      "metadata": {
        "id": "Fljxk9pd5gGC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the function with a query that is in the database if a query outside the database is asked it won't be able to answer\n",
        "response = answer_to_user_by_model(\"tell me about cats\")\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5krkPiaM5icB",
        "outputId": "8643b286-28eb-46c5-b56e-02e4a115391f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Based on the provided text, cats are independent pets that often enjoy their own space.  The second document is about dogs and is irrelevant to the query about cats.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}